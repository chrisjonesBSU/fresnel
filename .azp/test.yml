variables:
  image_root: glotzerlab/ci:2019.10
  private_image_root: joaander/ci:2019.10

stages:
- stage: build_test_cpu
  displayName: Unit test (CPU)
  dependsOn: []

  variables:
    enable_embree: 'on'
    enable_optix: 'off'

  jobs:
  - job: linux_cpu
    displayName: Linux
    strategy:
      matrix:
        gcc9_py38:
          unused: ""
        clang9_py38:
          unused: ""
        clang8_py38:
          unused: ""
        clang7_py38:
          unused: ""
        gcc8_py37:
          unused: ""
        gcc7_py37:
          unused: ""
        gcc6_py37:
          unused: ""
        gcc5_py37:
          unused: ""
        gcc48_py37:
          unused: ""
        clang6_py37:
          unused: ""
        clang5_py37:
          unused: ""
        clang4_py37:
          unused: ""
        gcc7_py36:
          unused: ""
    pool:
      vmImage: 'ubuntu-16.04'

    container:
      image: $(image_root)-$(System.JobName)
      options: -u 0

    steps:
    - template: templates/build_test.yml

  - job: mac_cpu
    displayName: Mac

    strategy:
      matrix:
        mac10_13:
          mac_image: macOS-10.13
        mac10_14:
          mac_image: macOS-10.14

    pool:
      vmImage: '$(mac_image)'

    steps:
    - script: brew install python tbb embree cmake ninja qhull numpy
      displayName: Brew install prereqs
    - script: python3 -m pip install pytest pillow
      displayName: Pip install prereqs
    # work around broken homebrew pybind11 package
    - script: |
        curl -sSL https://github.com/pybind/pybind11/archive/v2.4.2.tar.gz | tar -xzC ./ \
        && cd pybind11-2.4.2 \
        && mkdir build && cd build \
        && cmake ../ -DCMAKE_INSTALL_PREFIX=/usr/local -DPYBIND11_TEST=off -DPYTHON_EXECUTABLE=/usr/local/bin/python3 \
        && make install
      displayName: Manually install pybind11
      workingDirectory: $(Pipeline.Workspace)
    - template: templates/build_test.yml

- stage: build_test_gpu
  displayName: Unit test (GPU)
  dependsOn: []

  variables:
    enable_embree: 'off'
    enable_optix: 'on'

  jobs:
  - job: linux_gpu
    displayName: Linux
    strategy:
      matrix:

        optix60_cuda10_py37:
          unused: ""
        optix51_cuda9_py37:
          unused: ""
        optix51_cuda10_py37:
          unused: ""

    pool:
      name: 'GPU'
      demands:
        - short_jobs
        # optix6 jobs require a capable GPU
        - optix6

    container:
       image: $(private_image_root)-$(System.JobName)
       # bind mount needed to load OpTiX driver: https://github.com/NVIDIA/nvidia-docker/issues/990
       options: -u 0 --mount type=bind,source=/usr/lib/libnvidia-rtcore.so,target=/usr/lib/libnvidia-rtcore.so --mount type=bind,source=/usr/lib/libnvoptix.so,target=/usr/lib/libnvoptix.so --gpus=all --cpus=4 --memory=8g -e CUDA_VISIBLE_DEVICES

    workspace:
      clean: all

    steps:
    - template: templates/build_test.yml

- stage: doc
  displayName: Documentation
  dependsOn: []

  jobs:
  - job: sphinx_doc
    displayName: Sphinx
    pool:
      vmImage: 'ubuntu-16.04'

    container:
      image: $(image_root)-gcc7_py37
      options: -u 0

    workspace:
      clean: all

    steps:
    - checkout: self
      submodules: true
    - script: sphinx-build -b html -d _build/doctrees -W -n . _build/html
      displayName: (HTML)
      workingDirectory: doc
    - script: sphinx-build -b latex -d _build/doctrees -W -n . _build/latex
      displayName: (LaTeX)
      workingDirectory: doc
